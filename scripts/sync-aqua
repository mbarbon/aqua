#!/usr/bin/env python3

import argparse
import gzip
import json
import logging
import os
import sys
import time
import urllib, urllib.request

LOGGER = logging.getLogger('sync-aqua')
ITEM_BATCH = 100
SMALL_ITEM_BATCH = 10
USER_BATCH = 200
SMALL_USER_BATCH = 20

def make_url(base, path):
    parts = urllib.parse.urlparse(base)
    return urllib.parse.urlunparse((parts.scheme, parts.netloc, path, '', '', ''))

def req(url, content_type, data):
    headers = {
        'Content-Type': content_type,
        'Accept-Encoding': 'gzip',
    }
    if len(data) > 1024:
        data = gzip.compress(data)
        headers['Content-Encoding'] = 'gzip'
    bytes_sent = len(data)
    req = urllib.request.Request(
        url, data=data,
        headers=headers)
    with urllib.request.urlopen(req) as res:
        if res.getcode() != 200:
            raise Exception('Error in response')
        body = res.read()
        bytes_received = len(body)
        if body:
            compression = res.getheader('Content-Encoding')
            if compression == 'gzip':
                body = gzip.decompress(body)
            content_parts = res.getheader('Content-Type').split(';')
            if content_parts[0] == 'application/json':
                out_data = json.loads(body.decode('utf-8'))
            else:
                out_data = body
            return out_data, bytes_sent, bytes_received
        else:
            return None, bytes_sent, 0

def req_json(url, data):
    return req(url, 'application/json', json.dumps(data).encode('utf-8'))

def req_binary(url, data):
    return req(url, 'application/octet-stream', data)

class AquaSync(object):
    def __init__(self, base):
        self.base = base
        self.bytes_sent = 0
        self.bytes_received = 0

    def mbytes_sent(self):
        return self.bytes_sent / 1024. / 1024.

    def mbytes_received(self):
        return self.bytes_received / 1024. / 1024.

    def check_health(self):
        with urllib.request.urlopen(make_url(self.base, '/_is_enabled')) as res:
            if res.getcode() == 200 and res.read() == b'true':
                return True
            else:
                return False

    def req_json(self, endpoint, *args):
        url = make_url(self.base, endpoint)
        res, bytes_sent, bytes_received = req_json(url, *args)
        self.bytes_sent += bytes_sent
        self.bytes_received += bytes_received
        return res

    def req_binary(self, endpoint, *args):
        url = make_url(self.base, endpoint)
        res, bytes_sent, bytes_received = req_binary(url, *args)
        self.bytes_sent += bytes_sent
        self.bytes_received += bytes_received
        return res

    def fetch_user_ids(self, start, size):
        req = {'after_id': start, 'count': size}
        return self.req_json('/sync/all-user-ids', req)

    def fetch_anime_ids(self, start, size):
        req = {'after_id': start, 'count': size}
        return self.req_json('/sync/all-anime-ids', req)

    def fetch_manga_ids(self, start, size):
        req = {'after_id': start, 'count': size}
        return self.req_json('/sync/all-manga-ids', req)

    def fetch_item_ids(self, kind, start, size):
        if kind == 'anime':
            return self.fetch_anime_ids(start, size)
        elif kind == 'manga':
            return self.fetch_manga_ids(start, size)
        else:
            raise Exception("Invalid kind %s" % kind)

    def fetch_changed_users(self, id_map):
        req = {'users': id_map}
        return self.req_json('/sync/changed-users', req)

    def store_changed_users(self, users):
        req = {'users': users}
        return self.req_json('/sync/store-users', req)

    def fetch_changed_anime(self, id_map):
        req = {'anime': id_map}
        return self.req_json('/sync/changed-anime', req)

    def store_changed_anime(self, anime):
        req = {'anime': anime}
        return self.req_json('/sync/store-anime', req)

    def fetch_changed_manga(self, id_map):
        req = {'manga': id_map}
        return self.req_json('/sync/changed-manga', req)

    def store_changed_manga(self, manga):
        req = {'manga': manga}
        return self.req_json('/sync/store-manga', req)

    def fetch_changed_items(self, kind, id_map):
        if kind == 'anime':
            return self.fetch_changed_anime(id_map)
        elif kind == 'manga':
            return self.fetch_changed_manga(id_map)
        else:
            raise Exception("Invalid kind %s" % kind)

    def store_changed_items(self, kind, items):
        if kind == 'anime':
            return self.store_changed_anime(items)
        elif kind == 'manga':
            return self.store_changed_manga(items)
        else:
            raise Exception("Invalid kind %s" % kind)

    def upload_model(self, path, model_name):
        with open(path, 'rb') as fh:
            blob = fh.read()
        return self.req_binary('/sync/upload-model/' + model_name, blob)

    def commit_models(self):
        return self.req_json('/sync/commit-models', {})

def sync_aqua_items(kind, from_aqua, to_aqua, dry_run):
    LOGGER.info('  Fetching source %s ids', kind)
    from_item_ids = set()
    item_ids = from_aqua.fetch_item_ids(kind, 0, ITEM_BATCH)
    while item_ids[kind]:
        from_item_ids = from_item_ids | item_ids[kind].keys()
        item_ids = from_aqua.fetch_item_ids(kind, item_ids['last_page'], ITEM_BATCH)

    LOGGER.info('  Starting sync')
    total, synced, partial = 0, 0, time.time()
    item_ids = to_aqua.fetch_item_ids(kind, 0, ITEM_BATCH)
    while item_ids[kind]:
        from_item_ids = from_item_ids - item_ids[kind].keys()
        changed_items = from_aqua.fetch_changed_items(kind, item_ids[kind])
        if not dry_run:
            to_aqua.store_changed_items(kind, changed_items)
        total += len(item_ids[kind])
        synced += len(changed_items or [])
        if time.time() - partial >= 60:
            LOGGER.info('  Synced %d/%d %s', synced, total, kind)
            partial = time.time()
        item_ids = to_aqua.fetch_item_ids(kind, item_ids['last_page'], ITEM_BATCH)

    missing = list(from_item_ids)
    while missing:
        batch = missing[0:SMALL_ITEM_BATCH]
        id_map = {k: 0 for k in batch}
        changed_items = from_aqua.fetch_changed_items(kind, id_map)
        if not dry_run:
            to_aqua.store_changed_items(kind, changed_items)
        total += len(id_map)
        synced += len(changed_items or [])
        if time.time() - partial >= 60:
            LOGGER.info('  Synced %d/%d %s', synced, total, kind)
            partial = time.time()
        missing = missing[SMALL_ITEM_BATCH:]

    LOGGER.info('  Synced %d/%d %s', synced, total, kind)

def sync_aqua_users(from_aqua, to_aqua, dry_run):
    LOGGER.info('  Fetching source user ids')
    from_user_ids = set()
    user_ids = from_aqua.fetch_user_ids(0, USER_BATCH)
    while user_ids['users']:
        from_user_ids = from_user_ids | user_ids['users'].keys()
        user_ids = from_aqua.fetch_user_ids(user_ids['last_page'], USER_BATCH)

    LOGGER.info('  Starting sync')
    total, synced, partial = 0, 0, time.time()
    user_ids = to_aqua.fetch_user_ids(0, USER_BATCH)
    while user_ids['users']:
        from_user_ids = from_user_ids - user_ids['users'].keys()
        changed_users = from_aqua.fetch_changed_users(user_ids['users'])
        if not dry_run:
            to_aqua.store_changed_users(changed_users)
        total += len(user_ids['users'])
        synced += len(changed_users or [])
        if time.time() - partial >= 60:
            LOGGER.info('  Synced %d/%d users', synced, total)
            partial = time.time()
        user_ids = to_aqua.fetch_user_ids(user_ids['last_page'], USER_BATCH)

    missing = list(from_user_ids)
    while missing:
        batch = missing[0:SMALL_USER_BATCH]
        id_map = {k: 0 for k in batch}
        changed_users = from_aqua.fetch_changed_users(id_map)
        if not dry_run:
            to_aqua.store_changed_users(changed_users)
        total += len(id_map)
        synced += len(changed_users or [])
        if time.time() - partial >= 60:
            LOGGER.info('  Synced %d/%d users', synced, total)
            partial = time.time()
        missing = missing[SMALL_USER_BATCH:]

    LOGGER.info('  Synced %d/%d users', synced, total)

def sync_aqua_db(from_aqua, to_aqua, dry_run):
    LOGGER.info('Syncing anime %s -> %s', from_aqua.base, to_aqua.base)
    sync_aqua_items('anime', from_aqua, to_aqua, dry_run=dry_run)
    LOGGER.info('Syncing manga %s -> %s', from_aqua.base, to_aqua.base)
    sync_aqua_items('manga', from_aqua, to_aqua, dry_run=dry_run)
    LOGGER.info('Syncing users %s -> %s', from_aqua.base, to_aqua.base)
    sync_aqua_users(from_aqua, to_aqua, dry_run=dry_run)
    LOGGER.info('Done')

def cmd_sync_db(args):
    local = AquaSync(args.local)
    remote = AquaSync(args.remote)
    healthy_local = local.check_health()
    healthy_remote = remote.check_health()
    if not healthy_local:
        print('Local endpoint %s is not healthy' % args.local)
    if not healthy_remote:
        print('Remote endpoint %s is not healthy' % args.remote)
    if not (healthy_local and healthy_remote):
        sys.exit(1)

    if not (args.pull or args.push):
        args.pull = args.push = True
    if args.pull:
        sync_aqua_db(remote, local, dry_run=args.dry_run)
    if args.push:
        sync_aqua_db(local, remote, dry_run=args.dry_run)

    LOGGER.info("%s: sent %.02f MB, received %.02f MB",
                    local.base, local.mbytes_sent(), local.mbytes_received())
    LOGGER.info("%s: sent %.02f MB, received %.02f MB",
                    remote.base, remote.mbytes_sent(), remote.mbytes_received())

def push_aqua_models(directory, to_aqua, dry_run):
    LOGGER.info('Sending models')
    for model in ['anime-lfd-model', 'anime-lfd-model-airing', 'anime-lfd-user-model',
                      'anime-co-occurrency-model', 'anime-co-occurrency-model-airing',
                      'anime-user-sample']:
        source = os.path.join(directory, model)
        LOGGER.info('  Sending model %s', model)
        to_aqua.upload_model(source, model)
    LOGGER.info('Committing')
    to_aqua.commit_models()

def cmd_push_models(args):
    remote = AquaSync(args.remote)
    healthy_remote = remote.check_health()
    if not healthy_remote:
        print('Remote endpoint %s is not healthy' % args.remote)
    if not healthy_remote:
        sys.exit(1)

    push_aqua_models('maldump', remote, dry_run=args.dry_run)

    LOGGER.info("%s: sent %.02f MB, received %.02f MB",
                    remote.base, remote.mbytes_sent(), remote.mbytes_received())

def main():
    parser = argparse.ArgumentParser(description='Sync Aqua instances')
    def cmd_help(args):
        parser.print_help()
        print()
    parser.set_defaults(execute=cmd_help)
    subparsers = parser.add_subparsers(help='Functions')

    sync = subparsers.add_parser('sync-db', help='Sync Aqua databases')
    sync.add_argument('--pull', action='store_true',
                          help='Pull data from remote into local')
    sync.add_argument('--push', action='store_true',
                          help='Push data from local into remote')
    sync.add_argument('--dry-run', action='store_true',
                          help='Don\'t perform the store operation')
    sync.add_argument('local', help='Local Aqua instance')
    sync.add_argument('remote', help='Remote Aqua instance')
    sync.set_defaults(execute=cmd_sync_db)

    push_models = subparsers.add_parser('push-models', help='Push Aqua models')
    push_models.add_argument('--dry-run', action='store_true',
                                 help='Don\'t perform the commit operation')
    push_models.add_argument('remote', help='Remote Aqua instance')
    push_models.set_defaults(execute=cmd_push_models)

    args = parser.parse_args()
    args.execute(args)
    sys.exit(0)

if __name__ == '__main__':
    logging.basicConfig(
        level='INFO',
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    )
    main()
